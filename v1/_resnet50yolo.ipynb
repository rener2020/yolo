{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet50_backbone(resnet50: nn.Module):\n",
    "    features = list(resnet50.children())[:-2]\n",
    "    for feature in features[:-2]:\n",
    "        for parameter in feature.parameters():\n",
    "            parameter.requires_grad = False\n",
    "    return nn.Sequential(*features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           4,096\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "           Conv2d-11        [-1, 256, 112, 112]          16,384\n",
      "      BatchNorm2d-12        [-1, 256, 112, 112]             512\n",
      "           Conv2d-13        [-1, 256, 112, 112]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 112, 112]             512\n",
      "             ReLU-15        [-1, 256, 112, 112]               0\n",
      "       Bottleneck-16        [-1, 256, 112, 112]               0\n",
      "           Conv2d-17         [-1, 64, 112, 112]          16,384\n",
      "      BatchNorm2d-18         [-1, 64, 112, 112]             128\n",
      "             ReLU-19         [-1, 64, 112, 112]               0\n",
      "           Conv2d-20         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-21         [-1, 64, 112, 112]             128\n",
      "             ReLU-22         [-1, 64, 112, 112]               0\n",
      "           Conv2d-23        [-1, 256, 112, 112]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 112, 112]             512\n",
      "             ReLU-25        [-1, 256, 112, 112]               0\n",
      "       Bottleneck-26        [-1, 256, 112, 112]               0\n",
      "           Conv2d-27         [-1, 64, 112, 112]          16,384\n",
      "      BatchNorm2d-28         [-1, 64, 112, 112]             128\n",
      "             ReLU-29         [-1, 64, 112, 112]               0\n",
      "           Conv2d-30         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 112, 112]             128\n",
      "             ReLU-32         [-1, 64, 112, 112]               0\n",
      "           Conv2d-33        [-1, 256, 112, 112]          16,384\n",
      "      BatchNorm2d-34        [-1, 256, 112, 112]             512\n",
      "             ReLU-35        [-1, 256, 112, 112]               0\n",
      "       Bottleneck-36        [-1, 256, 112, 112]               0\n",
      "           Conv2d-37        [-1, 128, 112, 112]          32,768\n",
      "      BatchNorm2d-38        [-1, 128, 112, 112]             256\n",
      "             ReLU-39        [-1, 128, 112, 112]               0\n",
      "           Conv2d-40          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 56, 56]             256\n",
      "             ReLU-42          [-1, 128, 56, 56]               0\n",
      "           Conv2d-43          [-1, 512, 56, 56]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 56, 56]           1,024\n",
      "           Conv2d-45          [-1, 512, 56, 56]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-47          [-1, 512, 56, 56]               0\n",
      "       Bottleneck-48          [-1, 512, 56, 56]               0\n",
      "           Conv2d-49          [-1, 128, 56, 56]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 56, 56]             256\n",
      "             ReLU-51          [-1, 128, 56, 56]               0\n",
      "           Conv2d-52          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 56, 56]             256\n",
      "             ReLU-54          [-1, 128, 56, 56]               0\n",
      "           Conv2d-55          [-1, 512, 56, 56]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-57          [-1, 512, 56, 56]               0\n",
      "       Bottleneck-58          [-1, 512, 56, 56]               0\n",
      "           Conv2d-59          [-1, 128, 56, 56]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 56, 56]             256\n",
      "             ReLU-61          [-1, 128, 56, 56]               0\n",
      "           Conv2d-62          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 56, 56]             256\n",
      "             ReLU-64          [-1, 128, 56, 56]               0\n",
      "           Conv2d-65          [-1, 512, 56, 56]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-67          [-1, 512, 56, 56]               0\n",
      "       Bottleneck-68          [-1, 512, 56, 56]               0\n",
      "           Conv2d-69          [-1, 128, 56, 56]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 56, 56]             256\n",
      "             ReLU-71          [-1, 128, 56, 56]               0\n",
      "           Conv2d-72          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 56, 56]             256\n",
      "             ReLU-74          [-1, 128, 56, 56]               0\n",
      "           Conv2d-75          [-1, 512, 56, 56]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-77          [-1, 512, 56, 56]               0\n",
      "       Bottleneck-78          [-1, 512, 56, 56]               0\n",
      "           Conv2d-79          [-1, 256, 56, 56]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 56, 56]             512\n",
      "             ReLU-81          [-1, 256, 56, 56]               0\n",
      "           Conv2d-82          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 28, 28]             512\n",
      "             ReLU-84          [-1, 256, 28, 28]               0\n",
      "           Conv2d-85         [-1, 1024, 28, 28]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 28, 28]           2,048\n",
      "           Conv2d-87         [-1, 1024, 28, 28]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-89         [-1, 1024, 28, 28]               0\n",
      "       Bottleneck-90         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-91          [-1, 256, 28, 28]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 28, 28]             512\n",
      "             ReLU-93          [-1, 256, 28, 28]               0\n",
      "           Conv2d-94          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 28, 28]             512\n",
      "             ReLU-96          [-1, 256, 28, 28]               0\n",
      "           Conv2d-97         [-1, 1024, 28, 28]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-99         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-100         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-101          [-1, 256, 28, 28]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 28, 28]             512\n",
      "            ReLU-103          [-1, 256, 28, 28]               0\n",
      "          Conv2d-104          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 28, 28]             512\n",
      "            ReLU-106          [-1, 256, 28, 28]               0\n",
      "          Conv2d-107         [-1, 1024, 28, 28]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-109         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-110         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-111          [-1, 256, 28, 28]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 28, 28]             512\n",
      "            ReLU-113          [-1, 256, 28, 28]               0\n",
      "          Conv2d-114          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 28, 28]             512\n",
      "            ReLU-116          [-1, 256, 28, 28]               0\n",
      "          Conv2d-117         [-1, 1024, 28, 28]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-119         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-120         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-121          [-1, 256, 28, 28]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 28, 28]             512\n",
      "            ReLU-123          [-1, 256, 28, 28]               0\n",
      "          Conv2d-124          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 28, 28]             512\n",
      "            ReLU-126          [-1, 256, 28, 28]               0\n",
      "          Conv2d-127         [-1, 1024, 28, 28]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-129         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-130         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-131          [-1, 256, 28, 28]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 28, 28]             512\n",
      "            ReLU-133          [-1, 256, 28, 28]               0\n",
      "          Conv2d-134          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 28, 28]             512\n",
      "            ReLU-136          [-1, 256, 28, 28]               0\n",
      "          Conv2d-137         [-1, 1024, 28, 28]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-139         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-140         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-141          [-1, 512, 28, 28]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-143          [-1, 512, 28, 28]               0\n",
      "          Conv2d-144          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-146          [-1, 512, 14, 14]               0\n",
      "          Conv2d-147         [-1, 2048, 14, 14]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 14, 14]           4,096\n",
      "          Conv2d-149         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-151         [-1, 2048, 14, 14]               0\n",
      "      Bottleneck-152         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-153          [-1, 512, 14, 14]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-155          [-1, 512, 14, 14]               0\n",
      "          Conv2d-156          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-158          [-1, 512, 14, 14]               0\n",
      "          Conv2d-159         [-1, 2048, 14, 14]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-161         [-1, 2048, 14, 14]               0\n",
      "      Bottleneck-162         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-163          [-1, 512, 14, 14]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-165          [-1, 512, 14, 14]               0\n",
      "          Conv2d-166          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-168          [-1, 512, 14, 14]               0\n",
      "          Conv2d-169         [-1, 2048, 14, 14]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-171         [-1, 2048, 14, 14]               0\n",
      "      Bottleneck-172         [-1, 2048, 14, 14]               0\n",
      "================================================================\n",
      "Total params: 23,508,032\n",
      "Trainable params: 22,063,104\n",
      "Non-trainable params: 1,444,928\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 1146.14\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 1238.11\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(get_resnet50_backbone(resnet50).cuda(),(3,448,448))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnet50Yolo(nn.Module):\n",
    "    def __init__(self, resnet50):\n",
    "        super(Resnet50Yolo, self).__init__()\n",
    "        self.resnet50_backbone = get_resnet50_backbone(resnet50=resnet50)\n",
    "        self.last_conv = nn.Conv2d(2048, 1024, (3, 3), padding=1, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(7*7*1024, 4096)\n",
    "        self.fc2 = nn.Linear(4096, 7*7*30)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.resnet50_backbone(x)\n",
    "        x = self.last_conv(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_yolo = Resnet50Yolo(resnet50).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]           4,096\n",
      "       BatchNorm2d-6         [-1, 64, 112, 112]             128\n",
      "              ReLU-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          36,864\n",
      "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "           Conv2d-11        [-1, 256, 112, 112]          16,384\n",
      "      BatchNorm2d-12        [-1, 256, 112, 112]             512\n",
      "           Conv2d-13        [-1, 256, 112, 112]          16,384\n",
      "      BatchNorm2d-14        [-1, 256, 112, 112]             512\n",
      "             ReLU-15        [-1, 256, 112, 112]               0\n",
      "       Bottleneck-16        [-1, 256, 112, 112]               0\n",
      "           Conv2d-17         [-1, 64, 112, 112]          16,384\n",
      "      BatchNorm2d-18         [-1, 64, 112, 112]             128\n",
      "             ReLU-19         [-1, 64, 112, 112]               0\n",
      "           Conv2d-20         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-21         [-1, 64, 112, 112]             128\n",
      "             ReLU-22         [-1, 64, 112, 112]               0\n",
      "           Conv2d-23        [-1, 256, 112, 112]          16,384\n",
      "      BatchNorm2d-24        [-1, 256, 112, 112]             512\n",
      "             ReLU-25        [-1, 256, 112, 112]               0\n",
      "       Bottleneck-26        [-1, 256, 112, 112]               0\n",
      "           Conv2d-27         [-1, 64, 112, 112]          16,384\n",
      "      BatchNorm2d-28         [-1, 64, 112, 112]             128\n",
      "             ReLU-29         [-1, 64, 112, 112]               0\n",
      "           Conv2d-30         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-31         [-1, 64, 112, 112]             128\n",
      "             ReLU-32         [-1, 64, 112, 112]               0\n",
      "           Conv2d-33        [-1, 256, 112, 112]          16,384\n",
      "      BatchNorm2d-34        [-1, 256, 112, 112]             512\n",
      "             ReLU-35        [-1, 256, 112, 112]               0\n",
      "       Bottleneck-36        [-1, 256, 112, 112]               0\n",
      "           Conv2d-37        [-1, 128, 112, 112]          32,768\n",
      "      BatchNorm2d-38        [-1, 128, 112, 112]             256\n",
      "             ReLU-39        [-1, 128, 112, 112]               0\n",
      "           Conv2d-40          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 56, 56]             256\n",
      "             ReLU-42          [-1, 128, 56, 56]               0\n",
      "           Conv2d-43          [-1, 512, 56, 56]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 56, 56]           1,024\n",
      "           Conv2d-45          [-1, 512, 56, 56]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-47          [-1, 512, 56, 56]               0\n",
      "       Bottleneck-48          [-1, 512, 56, 56]               0\n",
      "           Conv2d-49          [-1, 128, 56, 56]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 56, 56]             256\n",
      "             ReLU-51          [-1, 128, 56, 56]               0\n",
      "           Conv2d-52          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 56, 56]             256\n",
      "             ReLU-54          [-1, 128, 56, 56]               0\n",
      "           Conv2d-55          [-1, 512, 56, 56]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-57          [-1, 512, 56, 56]               0\n",
      "       Bottleneck-58          [-1, 512, 56, 56]               0\n",
      "           Conv2d-59          [-1, 128, 56, 56]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 56, 56]             256\n",
      "             ReLU-61          [-1, 128, 56, 56]               0\n",
      "           Conv2d-62          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 56, 56]             256\n",
      "             ReLU-64          [-1, 128, 56, 56]               0\n",
      "           Conv2d-65          [-1, 512, 56, 56]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-67          [-1, 512, 56, 56]               0\n",
      "       Bottleneck-68          [-1, 512, 56, 56]               0\n",
      "           Conv2d-69          [-1, 128, 56, 56]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 56, 56]             256\n",
      "             ReLU-71          [-1, 128, 56, 56]               0\n",
      "           Conv2d-72          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 56, 56]             256\n",
      "             ReLU-74          [-1, 128, 56, 56]               0\n",
      "           Conv2d-75          [-1, 512, 56, 56]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 56, 56]           1,024\n",
      "             ReLU-77          [-1, 512, 56, 56]               0\n",
      "       Bottleneck-78          [-1, 512, 56, 56]               0\n",
      "           Conv2d-79          [-1, 256, 56, 56]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 56, 56]             512\n",
      "             ReLU-81          [-1, 256, 56, 56]               0\n",
      "           Conv2d-82          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 28, 28]             512\n",
      "             ReLU-84          [-1, 256, 28, 28]               0\n",
      "           Conv2d-85         [-1, 1024, 28, 28]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 28, 28]           2,048\n",
      "           Conv2d-87         [-1, 1024, 28, 28]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-89         [-1, 1024, 28, 28]               0\n",
      "       Bottleneck-90         [-1, 1024, 28, 28]               0\n",
      "           Conv2d-91          [-1, 256, 28, 28]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 28, 28]             512\n",
      "             ReLU-93          [-1, 256, 28, 28]               0\n",
      "           Conv2d-94          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 28, 28]             512\n",
      "             ReLU-96          [-1, 256, 28, 28]               0\n",
      "           Conv2d-97         [-1, 1024, 28, 28]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 28, 28]           2,048\n",
      "             ReLU-99         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-100         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-101          [-1, 256, 28, 28]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 28, 28]             512\n",
      "            ReLU-103          [-1, 256, 28, 28]               0\n",
      "          Conv2d-104          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 28, 28]             512\n",
      "            ReLU-106          [-1, 256, 28, 28]               0\n",
      "          Conv2d-107         [-1, 1024, 28, 28]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-109         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-110         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-111          [-1, 256, 28, 28]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 28, 28]             512\n",
      "            ReLU-113          [-1, 256, 28, 28]               0\n",
      "          Conv2d-114          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 28, 28]             512\n",
      "            ReLU-116          [-1, 256, 28, 28]               0\n",
      "          Conv2d-117         [-1, 1024, 28, 28]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-119         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-120         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-121          [-1, 256, 28, 28]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 28, 28]             512\n",
      "            ReLU-123          [-1, 256, 28, 28]               0\n",
      "          Conv2d-124          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 28, 28]             512\n",
      "            ReLU-126          [-1, 256, 28, 28]               0\n",
      "          Conv2d-127         [-1, 1024, 28, 28]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-129         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-130         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-131          [-1, 256, 28, 28]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 28, 28]             512\n",
      "            ReLU-133          [-1, 256, 28, 28]               0\n",
      "          Conv2d-134          [-1, 256, 28, 28]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 28, 28]             512\n",
      "            ReLU-136          [-1, 256, 28, 28]               0\n",
      "          Conv2d-137         [-1, 1024, 28, 28]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 28, 28]           2,048\n",
      "            ReLU-139         [-1, 1024, 28, 28]               0\n",
      "      Bottleneck-140         [-1, 1024, 28, 28]               0\n",
      "          Conv2d-141          [-1, 512, 28, 28]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-143          [-1, 512, 28, 28]               0\n",
      "          Conv2d-144          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-145          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-146          [-1, 512, 14, 14]               0\n",
      "          Conv2d-147         [-1, 2048, 14, 14]       1,048,576\n",
      "     BatchNorm2d-148         [-1, 2048, 14, 14]           4,096\n",
      "          Conv2d-149         [-1, 2048, 14, 14]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-151         [-1, 2048, 14, 14]               0\n",
      "      Bottleneck-152         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-153          [-1, 512, 14, 14]       1,048,576\n",
      "     BatchNorm2d-154          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-155          [-1, 512, 14, 14]               0\n",
      "          Conv2d-156          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-157          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-158          [-1, 512, 14, 14]               0\n",
      "          Conv2d-159         [-1, 2048, 14, 14]       1,048,576\n",
      "     BatchNorm2d-160         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-161         [-1, 2048, 14, 14]               0\n",
      "      Bottleneck-162         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-163          [-1, 512, 14, 14]       1,048,576\n",
      "     BatchNorm2d-164          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-165          [-1, 512, 14, 14]               0\n",
      "          Conv2d-166          [-1, 512, 14, 14]       2,359,296\n",
      "     BatchNorm2d-167          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-168          [-1, 512, 14, 14]               0\n",
      "          Conv2d-169         [-1, 2048, 14, 14]       1,048,576\n",
      "     BatchNorm2d-170         [-1, 2048, 14, 14]           4,096\n",
      "            ReLU-171         [-1, 2048, 14, 14]               0\n",
      "      Bottleneck-172         [-1, 2048, 14, 14]               0\n",
      "          Conv2d-173           [-1, 1024, 7, 7]      18,875,392\n",
      "         Flatten-174                [-1, 50176]               0\n",
      "          Linear-175                 [-1, 4096]     205,524,992\n",
      "          Linear-176                 [-1, 1470]       6,022,590\n",
      "================================================================\n",
      "Total params: 253,931,006\n",
      "Trainable params: 252,486,078\n",
      "Non-trainable params: 1,444,928\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 2.30\n",
      "Forward/backward pass size (MB): 1146.95\n",
      "Params size (MB): 968.67\n",
      "Estimated Total Size (MB): 2117.92\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet50_yolo, (3, 448, 448))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    def __init__(self, l_coord=5, l_noobj=0.5):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.l_coord = l_coord\n",
    "        self.l_noobj = l_noobj\n",
    "\n",
    "    @staticmethod\n",
    "    def position_loss(pred: torch.Tensor, truth: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def size_loss(pred: torch.Tensor, truth: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def size_loss(pred: torch.Tensor, truth: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def obj_box_loss(pred: torch.Tensor, truth: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    def noobj_box_loss(pred: torch.Tensor, truth: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def classification_loss(pred: torch.Tensor, truth: torch.Tensor):\n",
    "        pass\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, truth: torch.Tensor):\n",
    "        coord_mask = (truth[:,:,4] > 0).unsqueeze(-1).expand_as(truth)\n",
    "        noobj_mask = (truth[:,:,4] > 0).unsqueeze(-1).expand_as(truth)\n",
    "        \n",
    "        pred = pred.view(7, 7, 30)\n",
    "        loss = self.l_coord * self.position_loss(pred, truth) \\\n",
    "            + self.l_coord * self.size_loss(pred, truth) \\\n",
    "            + self.obj_box_loss(pred, truth) \\\n",
    "            + self.l_noobj * self.noobj_box_loss(pred, truth) \\\n",
    "            + self.classification_loss(pred, truth)\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
